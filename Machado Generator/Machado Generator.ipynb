{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src import MachadoLoader as ml\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ml.readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapedData = ml.mapData(data)\n",
    "trainData,testData = ml.separateData(mapedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData = [{'x':text[0:-1],'y':text[1:len(text)]} for text in trainData]\n",
    "testData = [{'x':text[0:-1],'y':text[1:len(text)]} for text in testData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_string(\"savePath\",\"/tmp/\",\"path to model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataType():\n",
    "    return tf.float32\n",
    "\n",
    "def create_input_fn(Data,batchSize=50):\n",
    "    data = Data\n",
    "\n",
    "    def input_fn():\n",
    "        np.random.shuffle(data)\n",
    "        batch = 0\n",
    "        batches = []\n",
    "        for _ in range(int(len(data)/batchSize)):\n",
    "            x = [d['x'] for d in data[batch:min(len(data),batch+batchSize)]]\n",
    "            y = [d['y'] for d in data[batch:min(len(data),batch+batchSize)]]\n",
    "            batch = batch+batchSize\n",
    "            batches.append((x,y))\n",
    "            print(\"new batch\")\n",
    "        batches = tf.constant(batches)\n",
    "        return batches\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = create_input_fn(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self,layers=2,rnn_size=128,n_chunks=28,chunk_size=28):\n",
    "        self.layers = layers\n",
    "        self.rnn_size = rnn_size\n",
    "        self.n_chunks = n_chunks\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "    \n",
    "    def model(self,x,n_classes):\n",
    "        layer = {'weights':tf.Variable(tf.random_normal([self.rnn_size,n_classes])),\n",
    "                 'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "        x = tf.transpose(x,[1,0,2])\n",
    "        x = tf.reshape(x,[-1,self.chunk_size])\n",
    "        x = tf.split(0,self.n_chunks,x)\n",
    "\n",
    "        lstm_cell = rnn_cell.BasicLSTMCell(self.rnn_size)\n",
    "        stacked_lstm = rnn_cell.MultiRNNCell([lstm_cell] * 2, state_is_tuple=True)\n",
    "\n",
    "        outputs, states = rnn.rnn(stacked_lstm, x, dtype=tf.float32)\n",
    "\n",
    "\n",
    "        output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def train(self,batch_gen, hm_epochs=3):\n",
    "        prediction = self.model(tf.placeholder('float', [None, self.n_chunks,self.chunk_size]),10)\n",
    "        cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for (epoch_x, epoch_y) in batch_gen():\n",
    "                epoch_x = epoch_x.reshape((len(epoch_x),n_chunks,chunk_size))\n",
    "                _, c = self.sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "        \n",
    "        self.prediction = prediction\n",
    "        \n",
    "    def score(dataX,dataY):\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:dataX.reshape((-1, n_chunks, chunk_size)), y:dataY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = RNN()\n",
    "r.train(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
